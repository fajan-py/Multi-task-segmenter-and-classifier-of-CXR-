{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 3324348,
          "sourceType": "datasetVersion",
          "datasetId": 576013
        }
      ],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "import kagglehub\n",
        "tawsifurrahman_covid19_radiography_database_path = kagglehub.dataset_download('tawsifurrahman/covid19-radiography-database')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "iszWpWr8Sxol"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# I installed torchmetrics for using Dice Score in segmentation and segmentation-models-pytorch for using Unet model\n",
        "!pip install torchmetrics\n",
        "!pip install segmentation-models-pytorch\n",
        "# Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18\n",
        "import torchmetrics\n",
        "from torchmetrics.segmentation import DiceScore\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from segmentation_models_pytorch import Unet\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T09:40:29.969903Z",
          "iopub.execute_input": "2025-01-27T09:40:29.970345Z",
          "iopub.status.idle": "2025-01-27T09:40:39.654104Z",
          "shell.execute_reply.started": "2025-01-27T09:40:29.970311Z",
          "shell.execute_reply": "2025-01-27T09:40:39.653453Z"
        },
        "id": "vcs2Hdu6Sxoo",
        "collapsed": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is dedicated to loading image paths, mask paths, and labels from the directory.\n",
        "def load_images_labels_and_masks(image_dir):\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "    labels = []\n",
        "    class_names = ['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity']\n",
        "\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_folder_images = os.path.join(image_dir, class_name, 'images')\n",
        "        class_folder_masks = os.path.join(image_dir, class_name, 'masks')\n",
        "        for filename in os.listdir(class_folder_images):\n",
        "            if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "                image_paths.append(os.path.join(class_folder_images, filename))\n",
        "                mask_paths.append(os.path.join(class_folder_masks, filename))\n",
        "                labels.append(class_name)\n",
        "\n",
        "\n",
        "\n",
        "    return image_paths, mask_paths, labels"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T09:40:44.053643Z",
          "iopub.execute_input": "2025-01-27T09:40:44.054095Z",
          "iopub.status.idle": "2025-01-27T09:40:44.059059Z",
          "shell.execute_reply.started": "2025-01-27T09:40:44.05407Z",
          "shell.execute_reply": "2025-01-27T09:40:44.0583Z"
        },
        "id": "pQ_CUP_3Sxop"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# I located and organized the paths to images, masks, and their labels within the downloaded COVID-19 Radiography dataset.\n",
        "dataset_path = tawsifurrahman_covid19_radiography_database_path\n",
        "image_dir = os.path.join(dataset_path, 'COVID-19_Radiography_Dataset')\n",
        "image_paths, mask_paths, labels = load_images_labels_and_masks(image_dir)"
      ],
      "metadata": {
        "id": "bXTrFJRYTbL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I used label encoder to convert text labels into numerical ones for my model\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T09:40:48.223297Z",
          "iopub.execute_input": "2025-01-27T09:40:48.223549Z",
          "iopub.status.idle": "2025-01-27T09:40:48.237789Z",
          "shell.execute_reply.started": "2025-01-27T09:40:48.22353Z",
          "shell.execute_reply": "2025-01-27T09:40:48.237125Z"
        },
        "id": "GlVC0H4PSxoq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Then, I splitted the dataset into train(%80) and test(%20)\n",
        "train_images, test_images, train_masks, test_masks, train_labels, test_labels = train_test_split(\n",
        "    image_paths, mask_paths, labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T09:40:49.823394Z",
          "iopub.execute_input": "2025-01-27T09:40:49.823688Z",
          "iopub.status.idle": "2025-01-27T09:40:49.841919Z",
          "shell.execute_reply.started": "2025-01-27T09:40:49.823666Z",
          "shell.execute_reply": "2025-01-27T09:40:49.841086Z"
        },
        "id": "f9NG7yXfSxoq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# In this step, I defined required transformations for my CXR photos\n",
        "my_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T09:40:50.943694Z",
          "iopub.execute_input": "2025-01-27T09:40:50.943948Z",
          "iopub.status.idle": "2025-01-27T09:40:50.948084Z",
          "shell.execute_reply.started": "2025-01-27T09:40:50.943927Z",
          "shell.execute_reply": "2025-01-27T09:40:50.947233Z"
        },
        "id": "GP7Bm3C3Sxor"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, I defined my costume dataset for loading and preprocessing images, masks and labels\n",
        "class CovidRadiographyDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, labels,transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        mask_path = self.mask_paths[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "\n",
        "        img = Image.open(image_path).convert('L')\n",
        "        mask = Image.open(mask_path).convert('L')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return img, mask, label\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T10:20:50.091954Z",
          "iopub.execute_input": "2025-01-27T10:20:50.092284Z",
          "iopub.status.idle": "2025-01-27T10:20:50.097762Z",
          "shell.execute_reply.started": "2025-01-27T10:20:50.09226Z",
          "shell.execute_reply": "2025-01-27T10:20:50.096912Z"
        },
        "id": "a2YDYHRfSxos"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Making train and test detasets\n",
        "train_dataset = CovidRadiographyDataset(train_images, train_masks, train_labels,transform=my_transform)\n",
        "test_dataset = CovidRadiographyDataset(test_images, test_masks, test_labels,transform=my_transform)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T10:20:54.971972Z",
          "iopub.execute_input": "2025-01-27T10:20:54.972319Z",
          "iopub.status.idle": "2025-01-27T10:20:54.976248Z",
          "shell.execute_reply.started": "2025-01-27T10:20:54.97229Z",
          "shell.execute_reply": "2025-01-27T10:20:54.975393Z"
        },
        "id": "0bcPSjh5Sxos"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Making train and test dataloader with batch size of 32\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=32, shuffle=True)\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T10:20:55.883711Z",
          "iopub.execute_input": "2025-01-27T10:20:55.883996Z",
          "iopub.status.idle": "2025-01-27T10:20:55.888617Z",
          "shell.execute_reply.started": "2025-01-27T10:20:55.883973Z",
          "shell.execute_reply": "2025-01-27T10:20:55.887695Z"
        },
        "id": "8Afs1k8sSxot"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying the right shape of images and masks for my model\n",
        "print(train_dataset[0][1].shape)\n",
        "print(train_dataset[0][0].shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T10:20:56.959066Z",
          "iopub.execute_input": "2025-01-27T10:20:56.959359Z",
          "iopub.status.idle": "2025-01-27T10:20:56.984595Z",
          "shell.execute_reply.started": "2025-01-27T10:20:56.959335Z",
          "shell.execute_reply": "2025-01-27T10:20:56.983872Z"
        },
        "id": "sB9sxTiJSxot"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the next step I defined a Multi Task Model in order to perform segmentation and classification simultaneously. I used **the encoder of the pretrained Unet model(Resnet18) as my feature extractor.** Then, I put a classification head for predicting the class as well as the built-in segmentor head for segmenting masks. It is worthy to note that using the built-in Resnet18 helped me to only pass each photo once through the model. Therefore, number of calculations and the amount of time needed for training can be minimised to a certain level. So, I can say that, **this architecture allows the model to learn shared representations for both tasks, potentially enhancing its performance.**"
      ],
      "metadata": {
        "id": "W2YwgQ01lCM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        self.unet = Unet(\n",
        "            encoder_name=\"resnet18\", encoder_weights=\"imagenet\", in_channels=1, classes=1\n",
        "        )\n",
        "\n",
        "        self.encoder = self.unet.encoder\n",
        "        self.decoder = self.unet.decoder\n",
        "        self.segmentation_head = self.unet.segmentation_head\n",
        "        self.classification_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.encoder.out_channels[-1], num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        encoder_features = self.encoder(x)\n",
        "        class_logits = self.classification_head(encoder_features[-1])\n",
        "        decoder_output = self.decoder(*encoder_features)\n",
        "        segmentation_mask = self.segmentation_head(decoder_output)\n",
        "\n",
        "        return class_logits, segmentation_mask\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T10:23:03.572148Z",
          "iopub.execute_input": "2025-01-27T10:23:03.57272Z",
          "iopub.status.idle": "2025-01-27T10:23:03.57813Z",
          "shell.execute_reply.started": "2025-01-27T10:23:03.57269Z",
          "shell.execute_reply": "2025-01-27T10:23:03.577345Z"
        },
        "id": "95wWxAzSSxov"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "model = MultiTaskModel(num_classes=4).to(device)\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "dice_metric = torchmetrics.segmentation.DiceScore(num_classes=1, include_background=True).to(device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-27T10:22:48.793121Z",
          "iopub.execute_input": "2025-01-27T10:22:48.793513Z",
          "iopub.status.idle": "2025-01-27T10:22:51.555169Z",
          "shell.execute_reply.started": "2025-01-27T10:22:48.793484Z",
          "shell.execute_reply": "2025-01-27T10:22:51.554326Z"
        },
        "collapsed": true,
        "id": "xWUu-2RKSxou"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# I trained my model for 5 epochs\n",
        "EPOCHS = 5\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_class_loss = 0.0\n",
        "    running_seg_loss = 0.0\n",
        "\n",
        "    for images, masks, labels in tqdm(train_dataloader):\n",
        "        images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
        "\n",
        "\n",
        "        class_logits, segmentation_mask = model(images)\n",
        "        class_loss = classification_loss_fn(class_logits, labels)\n",
        "        dice_loss = 1 - dice_metric(torch.sigmoid(segmentation_mask), masks.long())\n",
        "        total_loss = class_loss + dice_loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_class_loss += class_loss.item()\n",
        "        running_seg_loss += dice_loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/10], Classification Loss: {running_class_loss/len(train_dataloader):.4f}, Segmentation Loss (Dice): {running_seg_loss/len(train_dataloader):.4f}\")"
      ],
      "metadata": {
        "id": "1VrA5nM_V-AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for model evaluation\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    dice_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, labels in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            class_logits, segmentation_mask = model(images)\n",
        "\n",
        "            _, predicted_classes = torch.max(class_logits, 1)\n",
        "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            dice = dice_metric(torch.sigmoid(segmentation_mask), masks.long())\n",
        "            dice_scores.append(dice.item())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(classification_report(all_labels, all_predictions))\n",
        "    print(f\"Mean Dice Score: {np.mean(dice_scores)}\")\n"
      ],
      "metadata": {
        "id": "uQr-YF0p39Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model achieved 95% accuracy in classifying and 0.977 Mean Dice Score in segmenting lung X-rays for four lung conditions.\n",
        "evaluate_model(model, test_dataloader, device)"
      ],
      "metadata": {
        "id": "M6o0Cp6H4X_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b67745-3386-4727-a2db-b6c098bddd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 133/133 [00:46<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9454287739192062\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95       701\n",
            "           1       0.97      0.89      0.92      1175\n",
            "           2       0.94      0.96      0.95      2085\n",
            "           3       0.98      0.96      0.97       272\n",
            "\n",
            "    accuracy                           0.95      4233\n",
            "   macro avg       0.95      0.95      0.95      4233\n",
            "weighted avg       0.95      0.95      0.95      4233\n",
            "\n",
            "Mean Dice Score: 0.9774674181651352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For last step, I added some visualization of my multi task model for the ease of comparison\n",
        "# input images, model's segmnetation and masks are visualized side by side\n",
        "# besides, I visualized model classification vs the actual class of the photo\n",
        "for images, masks, labels in tqdm(test_dataloader):\n",
        "    images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
        "\n",
        "\n",
        "    class_logits, segmentation_mask = model(images)\n",
        "\n",
        "\n",
        "    plt.figure(1, figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(images[0].cpu().squeeze(), cmap='gray')\n",
        "    plt.title('Input Image')\n",
        "    plt.subplot(1, 3, 2)\n",
        "    seg = torch.round(torch.sigmoid(segmentation_mask[0].cpu().detach().squeeze()))\n",
        "    plt.imshow(seg, cmap='gray')\n",
        "    plt.title('Segmentation')\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(masks[0].cpu().detach().squeeze(), cmap='gray')\n",
        "    plt.title('Segmentation Mask')\n",
        "\n",
        "    plt.suptitle(f'Input Image and Segmentation Mask; label: {labels[0].item()}, prediction: {class_logits[0].argmax().item()}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "P0thCgyXMXK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}